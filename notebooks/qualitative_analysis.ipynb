{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9770c0bf",
   "metadata": {},
   "source": [
    "# AI-Enhanced Qualitative Data Analysis\n",
    "\n",
    "This notebook processes Excel workbooks containing qualitative data and uses AI models (BERTopic or Top2Vec) to automatically extract themes and topics for qualitative data analysis (QDA).\n",
    "\n",
    "## Features\n",
    "- Load multiple Excel sheets/tabs\n",
    "- Extract qualitative text from specified columns\n",
    "- Apply BERTopic for hierarchical theme extraction\n",
    "- Interactive visualizations\n",
    "- Export results for QDA tools (Taguette, QualCoder, etc.)\n",
    "\n",
    "## Setup\n",
    "1. Place your Excel workbook in the `data/raw/` directory\n",
    "2. Update the `excel_file` path below\n",
    "3. Customize column names if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c753fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries if not already installed\n",
    "# Uncomment the line below if running in an environment without these packages\n",
    "# !uv install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Excel workbook\n",
    "# Replace 'your_workbook.xlsx' with the path to your Excel file\n",
    "excel_file = '../data/raw/callcenterdata.xlsx'\n",
    "\n",
    "# Load all sheets into a dictionary of DataFrames\n",
    "try:\n",
    "    sheets_dict = pd.read_excel(excel_file, sheet_name=None)\n",
    "    print(f\"✓ Successfully loaded workbook: {excel_file}\")\n",
    "    print(f\"Loaded sheets: {list(sheets_dict.keys())}\")\n",
    "    \n",
    "    # Display basic info about each sheet\n",
    "    for sheet_name, df in sheets_dict.items():\n",
    "        print(f\"  - {sheet_name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Error: File '{excel_file}' not found.\")\n",
    "    print(\"Please place your Excel file in the data/raw/ directory and update the path above.\")\n",
    "    sheets_dict = {}\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading Excel file: {e}\")\n",
    "    sheets_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f78826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract qualitative text data\n",
    "# Configure text column names to extract from\n",
    "text_columns = ['Contact Reason', 'Contact Reason Detail']  # Add your column names here\n",
    "\n",
    "all_texts = []\n",
    "text_sources = []  # Track which sheet each text came from\n",
    "\n",
    "if sheets_dict:\n",
    "    for sheet_name, df in sheets_dict.items():\n",
    "        print(f\"\\nProcessing sheet: {sheet_name}\")\n",
    "        \n",
    "        # Find text columns in this sheet\n",
    "        available_text_cols = [col for col in text_columns if col in df.columns]\n",
    "        \n",
    "        if available_text_cols:\n",
    "            print(f\"  Found text columns: {available_text_cols}\")\n",
    "            \n",
    "            # Extract text from each available column\n",
    "            for col in available_text_cols:\n",
    "                texts = df[col].dropna().astype(str).tolist()\n",
    "                all_texts.extend(texts)\n",
    "                text_sources.extend([f\"{sheet_name}:{col}\"] * len(texts))\n",
    "                print(f\"    - {col}: {len(texts)} texts extracted\")\n",
    "        else:\n",
    "            print(f\"  Warning: No text columns found in '{sheet_name}'. Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\n✓ Total texts extracted: {len(all_texts)}\")\n",
    "    \n",
    "    if all_texts:\n",
    "        print(f\"Sample text: {all_texts[0][:100]}...\")\n",
    "        \n",
    "        # Save processed data\n",
    "        processed_df = pd.DataFrame({\n",
    "            'text': all_texts,\n",
    "            'source': text_sources\n",
    "        })\n",
    "        processed_df.to_csv('../data/processed/extracted_texts.csv', index=False)\n",
    "        print(\"✓ Processed texts saved to data/processed/extracted_texts.csv\")\n",
    "    else:\n",
    "        print(\"✗ No texts were extracted. Please check your column names.\")\n",
    "else:\n",
    "    print(\"No workbook loaded. Please check Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ec1f6",
   "metadata": {},
   "source": [
    "### Optional: Text Quality Filtering\n",
    "\n",
    "Before running the AI model, you can filter out texts that are too short or too long. This helps improve topic quality by removing:\n",
    "- Very short responses (e.g., \"N/A\", \"None\", single words)\n",
    "- Extremely long texts that might be outliers\n",
    "- Empty or near-empty entries\n",
    "\n",
    "Adjust `min_text_length` and `max_text_length` based on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bee646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.5: Filter texts by quality (optional)\n",
    "# Remove texts that are too short or likely not meaningful\n",
    "\n",
    "min_text_length = 10  # Minimum characters per text\n",
    "max_text_length = 10000  # Maximum characters (remove outliers)\n",
    "\n",
    "if all_texts:\n",
    "    original_count = len(all_texts)\n",
    "    \n",
    "    # Filter texts and their sources together\n",
    "    filtered_data = [\n",
    "        (text, source) for text, source in zip(all_texts, text_sources)\n",
    "        if min_text_length <= len(str(text)) <= max_text_length\n",
    "    ]\n",
    "    \n",
    "    if filtered_data:\n",
    "        all_texts, text_sources = zip(*filtered_data)\n",
    "        all_texts = list(all_texts)\n",
    "        text_sources = list(text_sources)\n",
    "        \n",
    "        removed_count = original_count - len(all_texts)\n",
    "        print(f\"✓ Text filtering complete:\")\n",
    "        print(f\"  - Kept: {len(all_texts)} texts\")\n",
    "        print(f\"  - Removed: {removed_count} texts (too short or too long)\")\n",
    "        print(f\"  - Length range: {min_text_length}-{max_text_length} characters\")\n",
    "        \n",
    "        # Show distribution\n",
    "        lengths = [len(str(t)) for t in all_texts]\n",
    "        print(f\"  - Average length: {np.mean(lengths):.0f} characters\")\n",
    "        print(f\"  - Median length: {np.median(lengths):.0f} characters\")\n",
    "    else:\n",
    "        print(\"✗ Warning: All texts were filtered out. Try adjusting min/max length.\")\n",
    "else:\n",
    "    print(\"No texts to filter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a39a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply BERTopic for theme extraction\n",
    "model_choice = globals().get('model_choice', 'bertopic')\n",
    "\n",
    "if all_texts:\n",
    "    print(f\"Running {model_choice.upper()} analysis on {len(all_texts)} texts...\")\n",
    "    \n",
    "    # Handle large datasets by sampling\n",
    "    if len(all_texts) > 50000:\n",
    "        print(f\"Dataset is large ({len(all_texts)} texts). Sampling to 50,000 for analysis to avoid memory issues.\")\n",
    "        sample_indices = np.random.choice(len(all_texts), 50000, replace=False)\n",
    "        analysis_texts = [all_texts[i] for i in sample_indices]\n",
    "        analysis_sources = [text_sources[i] for i in sample_indices]\n",
    "    else:\n",
    "        analysis_texts = all_texts\n",
    "        analysis_sources = text_sources\n",
    "\n",
    "    # Import additional libraries for custom models\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "    \n",
    "    # Initialize BERTopic model with optimized settings for large datasets\n",
    "    topic_model = BERTopic(\n",
    "        language=\"english\",\n",
    "        calculate_probabilities=False,  # Set to False to reduce memory usage\n",
    "        verbose=True,\n",
    "        min_topic_size=10,  # Increased from 5 to reduce number of topics and memory\n",
    "        nr_topics=\"auto\",   # Auto-determine number of topics\n",
    "        low_memory=True,  # Enable low memory mode for large datasets\n",
    "        umap_model=UMAP(n_jobs=1),  # Disable multiprocessing in UMAP\n",
    "        hdbscan_model=HDBSCAN(core_dist_n_jobs=1)  # Disable multiprocessing in HDBSCAN\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    topics, probabilities = topic_model.fit_transform(analysis_texts)\n",
    "    \n",
    "    # Get topic information\n",
    "    theme_info = topic_model.get_topic_info()\n",
    "    \n",
    "    print(f\"\\n✓ BERTopic identified {len(theme_info)-1} topics (excluding outliers)\")\n",
    "    \n",
    "    # Display extracted themes\n",
    "    display(theme_info.head(10))\n",
    "    \n",
    "else:\n",
    "    print(\"No texts available for analysis. Please check Step 2.\")\n",
    "    theme_info = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44012421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize topics\n",
    "# Safely get variables that may not exist in the current kernel/session\n",
    "theme_info = globals().get('theme_info', None)\n",
    "model_choice = globals().get('model_choice', 'bertopic')\n",
    "topic_model = globals().get('topic_model', None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import plotly.io as pio\n",
    "\n",
    "# Prefer a non-blocking renderer for notebooks; HTML embedding fallback is safest\n",
    "try:\n",
    "    pio.renderers.default = 'notebook_connected'\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def _display_fig(fig, title=None):\n",
    "    \"\"\"Embed a Plotly figure as HTML to avoid renderer blocking issues.\"\"\"\n",
    "    try:\n",
    "        html = fig.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "        if title:\n",
    "            display(HTML(f\"<h4>{title}</h4>\"))\n",
    "        display(HTML(html))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to render figure as HTML: {e}\")\n",
    "\n",
    "if theme_info is not None and topic_model is not None:\n",
    "    print(\"Generating visualizations...\")\n",
    "    \n",
    "    # Topic visualization\n",
    "    try:\n",
    "        fig_topics = topic_model.visualize_topics()\n",
    "        _display_fig(fig_topics, title='Topic Overview')\n",
    "    except Exception as e:\n",
    "        print(f\"Topic visualization failed: {e}\")\n",
    "    \n",
    "    # Topic hierarchy (if enough topics and not too many)\n",
    "    try:\n",
    "        if len(theme_info) > 3 and len(theme_info) < 200:\n",
    "            fig_hierarchy = topic_model.visualize_hierarchy()\n",
    "            _display_fig(fig_hierarchy, title='Topic Hierarchy')\n",
    "        else:\n",
    "            if len(theme_info) >= 200:\n",
    "                print('Skipping hierarchy visualization: too many topics to render.')\n",
    "    except Exception as e:\n",
    "        print(f\"Hierarchy visualization failed: {e}\")\n",
    "    \n",
    "    # Topic distribution\n",
    "    try:\n",
    "        fig_barchart = topic_model.visualize_barchart(top_n_topics=10)\n",
    "        _display_fig(fig_barchart, title='Top Topics Barchart')\n",
    "    except Exception as e:\n",
    "        print(f\"Barchart visualization failed: {e}\")\n",
    "    \n",
    "else:\n",
    "    if theme_info is None:\n",
    "        print(\"No themes available for visualization. Run the analysis cells first.\")\n",
    "    elif model_choice == 'bertopic' and topic_model is None:\n",
    "        print(\"BERTopic model object not found in the session. Re-run the BERTopic analysis cell.\")\n",
    "    else:\n",
    "        print(\"No visualizations available for the current configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Export themes for validation/import into QDA tool\n",
    "if theme_info is not None:\n",
    "    # Export to CSV\n",
    "    output_file = f\"../data/results/extracted_themes_{model_choice}.csv\"\n",
    "    theme_info.to_csv(output_file, index=False)\n",
    "    print(f\"✓ Themes exported to '{output_file}'\")\n",
    "    \n",
    "    # Export detailed topic information\n",
    "    # Get topic representations\n",
    "    topic_representations = {}\n",
    "    for topic_id in theme_info['Topic'].unique():\n",
    "        if topic_id != -1:  # Skip outlier topic\n",
    "            words = topic_model.get_topic(topic_id)\n",
    "            topic_representations[topic_id] = words\n",
    "    \n",
    "    # Create detailed export\n",
    "    detailed_themes = []\n",
    "    for topic_id, words in topic_representations.items():\n",
    "        detailed_themes.append({\n",
    "            'topic_id': topic_id,\n",
    "            'topic_name': f\"Topic_{topic_id}\",\n",
    "            'top_words': ', '.join([word for word, _ in words[:10]]),\n",
    "            'word_scores': ', '.join([f\"{word}:{score:.3f}\" for word, score in words[:10]]),\n",
    "            'document_count': theme_info[theme_info['Topic'] == topic_id]['Count'].iloc[0]\n",
    "        })\n",
    "    \n",
    "    detailed_df = pd.DataFrame(detailed_themes)\n",
    "    detailed_output = f\"../data/results/detailed_themes_{model_choice}.csv\"\n",
    "    detailed_df.to_csv(detailed_output, index=False)\n",
    "    print(f\"✓ Detailed themes exported to '{detailed_output}'\")\n",
    "    \n",
    "    # Export text-topic assignments for QDA validation\n",
    "    text_topics_df = pd.DataFrame({\n",
    "        'text': analysis_texts,\n",
    "        'source': analysis_sources,\n",
    "        'topic': topics,\n",
    "        'topic_probability': [None] * len(topics)  # Probabilities disabled for memory efficiency\n",
    "    })\n",
    "\n",
    "    \n",
    "    assignments_file = f\"../data/results/text_topic_assignments_{model_choice}.csv\"\n",
    "    text_topics_df.to_csv(assignments_file, index=False)\n",
    "    print(f\"✓ Text-topic assignments exported to '{assignments_file}'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPORT COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Files ready for import into QDA tools like:\")\n",
    "    print(\"- Taguette (import CSV files)\")\n",
    "    print(\"- QualCoder (import CSV files)\")\n",
    "    print(\"- NVivo (import CSV files)\")\n",
    "    print(\"- ATLAS.ti (import CSV files)\")\n",
    "    \n",
    "else:\n",
    "    print(\"No themes to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b682b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Validate AI-generated themes** in your QDA tool\n",
    "2. **Refine topics** by merging, splitting, or renaming as needed\n",
    "3. **Code additional texts** using the validated themes\n",
    "4. **Export coded data** for further quantitative analysis\n",
    "\n",
    "## Tips for Better Results\n",
    "\n",
    "- **Preprocessing**: Clean your text data before analysis (remove noise, standardize formats)\n",
    "- **Model Tuning**: Adjust `min_topic_size` in BERTopic for more/fewer topics\n",
    "- **Language**: Set the correct language if your texts aren't in English\n",
    "- **Scale**: For large datasets (>10k texts), consider running on Databricks Community Edition\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Memory issues**: Reduce `min_topic_size` or use Top2Vec instead\n",
    "- **Poor topics**: Preprocess text better or try different model settings\n",
    "- **No texts found**: Check column names in your Excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qdalocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
