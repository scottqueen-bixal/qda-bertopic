{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9770c0bf",
   "metadata": {},
   "source": [
    "# AI-Enhanced Qualitative Data Analysis\n",
    "\n",
    "This notebook processes Excel workbooks containing qualitative data and uses AI models (BERTopic or Top2Vec) to automatically extract themes and topics for qualitative data analysis (QDA).\n",
    "\n",
    "## Features\n",
    "- Load multiple Excel sheets/tabs\n",
    "- Extract qualitative text from specified columns\n",
    "- Apply BERTopic for hierarchical theme extraction\n",
    "- Interactive visualizations\n",
    "- Export results for QDA tools (Taguette, QualCoder, etc.)\n",
    "\n",
    "## Setup\n",
    "1. Place your Excel workbook in the `data/raw/` directory\n",
    "2. Update the `excel_file` path below\n",
    "3. Customize column names if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c753fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries if not already installed\n",
    "# Uncomment the line below if running in an environment without these packages\n",
    "# !uv install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa16acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705b4fe005354f86b908ba99b19f32eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import openpyxl  # Faster for large files than pandas default\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import glob\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "umap_model = UMAP(n_neighbors=3, n_components=3, min_dist=0.05)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=80, min_samples=40,\n",
    "                        gen_min_span_tree=True,\n",
    "                        prediction_data=True)\n",
    "\n",
    "stopwords = list(stopwords.words('english')) + ['to', 'the', 'im', 'for', 'on']\n",
    "\n",
    "# we add this to remove stopwords that can pollute topcs\n",
    "vectorizer_model = CountVectorizer(\n",
    "  ngram_range=(1, 2), \n",
    "  stop_words=stopwords\n",
    ")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280f4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Excel file: ../data/raw/callcenterdata.xlsx\n",
      "Loading workbook (this may take a moment for large files)...\n",
      "âœ“ Successfully loaded workbook in 1.7 seconds\n",
      "Loaded 3 sheets: ['COLA FONL Unique', 'General Inqury Unique', 'Contact Reason Details']\n",
      "  - COLA FONL Unique: 2,517 rows, 11 columns\n",
      "  - General Inqury Unique: 1,583 rows, 11 columns\n",
      "  - Contact Reason Details: 31,879 rows, 11 columns\n",
      "\n",
      "COMPLETE - Total rows across all sheets: 35,979\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the Excel workbook\n",
    "# Replace 'your_workbook.xlsx' with the path to your Excel file\n",
    "# Find the first .xlsx file in the data/raw directory\n",
    "excel_files = glob.glob('../data/raw/*.xlsx')\n",
    "\n",
    "if excel_files:\n",
    "    excel_file = excel_files[0]  # Use the first Excel file found\n",
    "    print(f\"Found Excel file: {excel_file}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading workbook (this may take a moment for large files)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Use openpyxl engine for better performance on large files\n",
    "        # Load all sheets into a dictionary of DataFrames\n",
    "        sheets_dict = pd.read_excel(excel_file, sheet_name=None, engine='openpyxl')\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"âœ“ Successfully loaded workbook in {load_time:.1f} seconds\")\n",
    "        print(f\"Loaded {len(sheets_dict)} sheets: {list(sheets_dict.keys())}\")\n",
    "        \n",
    "        # Display basic info about each sheet\n",
    "        total_rows = 0\n",
    "        for sheet_name, df in sheets_dict.items():\n",
    "            rows = df.shape[0]\n",
    "            cols = df.shape[1]\n",
    "            total_rows += rows\n",
    "            print(f\"  - {sheet_name}: {rows:,} rows, {cols} columns\")\n",
    "        \n",
    "        print(f\"\\nCOMPLETE - Total rows across all sheets: {total_rows:,}\")\n",
    "        \n",
    "        # Optional: For very large files, load sheets on-demand later\n",
    "        # Instead of loading all at once, you could do:\n",
    "        # xl = pd.ExcelFile(excel_file, engine='openpyxl')\n",
    "        # Then load specific sheets in Step 2: df = xl.parse(sheet_name)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— Error: File '{excel_file}' not found.\")\n",
    "        print(\"Please place your Excel file in the data/raw/ directory and update the path above.\")\n",
    "        sheets_dict = {}\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error loading Excel file: {e}\")\n",
    "        sheets_dict = {}\n",
    "else:\n",
    "    excel_file = None\n",
    "    sheets_dict = {}\n",
    "    print(\"âœ— No Excel files found in ../data/raw/\")\n",
    "    print(\"Please place an Excel workbook (.xlsx) in the data/raw/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f78826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sheet: COLA FONL Unique\n",
      "  Found text columns: ['Contact Reason', 'Contact Reason Detail', 'Comment']\n",
      "    - Contact Reason: 2517 texts extracted\n",
      "    - Contact Reason Detail: 2517 texts extracted\n",
      "    - Comment: 2517 texts extracted\n",
      "\n",
      "Processing sheet: General Inqury Unique\n",
      "  Found text columns: ['Contact Reason', 'Contact Reason Detail', 'Comment']\n",
      "    - Contact Reason: 1583 texts extracted\n",
      "    - Contact Reason Detail: 1583 texts extracted\n",
      "    - Comment: 1582 texts extracted\n",
      "\n",
      "Processing sheet: Contact Reason Details\n",
      "  Found text columns: ['Contact Reason', 'Contact Reason Detail', 'Comment']\n",
      "    - Contact Reason: 31879 texts extracted\n",
      "    - Contact Reason Detail: 31879 texts extracted\n",
      "    - Comment: 31865 texts extracted\n",
      "\n",
      "âœ“ Total texts extracted: 107922\n",
      "Sample text: COLA/FONL Issues...\n",
      "âœ“ Processed texts saved to data/processed/extracted_texts.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract qualitative text data\n",
    "# Configure text column names to extract from\n",
    "text_columns = ['Contact Reason', 'Contact Reason Detail', 'Comment']  # Add your column names here\n",
    "\n",
    "all_texts = []\n",
    "text_sources = []  # Track which sheet each text came from\n",
    "\n",
    "if sheets_dict:\n",
    "    for sheet_name, df in sheets_dict.items():\n",
    "        print(f\"\\nProcessing sheet: {sheet_name}\")\n",
    "        \n",
    "        # Find text columns in this sheet\n",
    "        available_text_cols = [col for col in text_columns if col in df.columns]\n",
    "        \n",
    "        if available_text_cols:\n",
    "            print(f\"  Found text columns: {available_text_cols}\")\n",
    "            \n",
    "            # Extract text from each available column\n",
    "            for col in available_text_cols:\n",
    "                texts = df[col].dropna().astype(str).tolist()\n",
    "                all_texts.extend(texts)\n",
    "                text_sources.extend([f\"{sheet_name}:{col}\"] * len(texts))\n",
    "                print(f\"    - {col}: {len(texts)} texts extracted\")\n",
    "        else:\n",
    "            print(f\"  Warning: No text columns found in '{sheet_name}'. Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Total texts extracted: {len(all_texts)}\")\n",
    "    \n",
    "    if all_texts:\n",
    "        print(f\"Sample text: {all_texts[0][:100]}...\")\n",
    "        \n",
    "        # Save processed data\n",
    "        processed_df = pd.DataFrame({\n",
    "            'text': all_texts,\n",
    "            'source': text_sources\n",
    "        })\n",
    "        processed_df.to_csv('../data/processed/extracted_texts.csv', index=False)\n",
    "        print(\"âœ“ Processed texts saved to data/processed/extracted_texts.csv\")\n",
    "    else:\n",
    "        print(\"âœ— No texts were extracted. Please check your column names.\")\n",
    "else:\n",
    "    print(\"No workbook loaded. Please check Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a99e6f",
   "metadata": {},
   "source": [
    "# Generate Unique comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d679fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Extracting unique comments from all sheets...\n",
      "  Found 'Comment' column in sheet: COLA FONL Unique\n",
      "    - Extracted 2517 comments\n",
      "  Found 'Comment' column in sheet: General Inqury Unique\n",
      "    - Extracted 1582 comments\n",
      "  Found 'Comment' column in sheet: Contact Reason Details\n",
      "    - Extracted 31865 comments\n",
      "\n",
      "âœ“ Comment extraction complete:\n",
      "  - Total comments extracted: 35964\n",
      "  - Duplicates removed: 11993\n",
      "  - Unique comments: 23971\n",
      "âœ“ Unique comments saved to data/processed/unique_comments.csv\n",
      "Sample comment:  \tADDRESS VERIFICATION FOR PERMIT FL-I-15562...\n"
     ]
    }
   ],
   "source": [
    "# Step 2.25: Extract unique comments from all sheets\n",
    "# This creates a deduplicated list of all comments across the workbook\n",
    "\n",
    "all_comments = []\n",
    "comment_sources = []  # Track which sheet each comment came from\n",
    "\n",
    "if sheets_dict:\n",
    "    print(\"\\nðŸ” Extracting unique comments from all sheets...\")\n",
    "    \n",
    "    for sheet_name, df in sheets_dict.items():\n",
    "        # Look for \"Comment\" column (case-insensitive)\n",
    "        comment_cols = [col for col in df.columns if col.lower() == 'comment']\n",
    "        \n",
    "        if comment_cols:\n",
    "            comment_col = comment_cols[0]  # Take the first match\n",
    "            print(f\"  Found 'Comment' column in sheet: {sheet_name}\")\n",
    "            \n",
    "            # Extract comments, remove nulls and empty strings\n",
    "            comments = df[comment_col].dropna().astype(str)\n",
    "            comments = comments[comments.str.strip() != '']  # Remove empty/whitespace-only\n",
    "            \n",
    "            comment_list = comments.tolist()\n",
    "            all_comments.extend(comment_list)\n",
    "            comment_sources.extend([f\"{sheet_name}:{comment_col}\"] * len(comment_list))\n",
    "            \n",
    "            print(f\"    - Extracted {len(comment_list)} comments\")\n",
    "        else:\n",
    "            print(f\"  No 'Comment' column found in sheet: {sheet_name}\")\n",
    "    \n",
    "    if all_comments:\n",
    "        # Create DataFrame and deduplicate\n",
    "        comments_df = pd.DataFrame({\n",
    "            'Comment': all_comments,\n",
    "            'source': comment_sources\n",
    "        })\n",
    "        \n",
    "        # Track duplicates before removing\n",
    "        original_count = len(comments_df)\n",
    "        comments_df = comments_df.drop_duplicates(subset=['Comment'], keep='first')\n",
    "        unique_count = len(comments_df)\n",
    "        duplicates_removed = original_count - unique_count\n",
    "        \n",
    "        print(f\"\\nâœ“ Comment extraction complete:\")\n",
    "        print(f\"  - Total comments extracted: {original_count}\")\n",
    "        print(f\"  - Duplicates removed: {duplicates_removed}\")\n",
    "        print(f\"  - Unique comments: {unique_count}\")\n",
    "        \n",
    "        # Export unique comments (only the Comment column)\n",
    "        unique_comments_df = comments_df[['Comment']].copy()\n",
    "        unique_comments_df.to_csv('../data/processed/unique_comments.csv', index=False)\n",
    "        print(\"âœ“ Unique comments saved to data/processed/unique_comments.csv\")\n",
    "        \n",
    "        # Show sample\n",
    "        if unique_count > 0:\n",
    "            print(f\"Sample comment: {unique_comments_df['Comment'].iloc[0][:100]}...\")\n",
    "    else:\n",
    "        print(\"âœ— No comments found in any sheets with 'Comment' column.\")\n",
    "else:\n",
    "    print(\"No workbook loaded. Please check Step 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a39a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 07:08:01,896 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BERTOPIC analysis on 107922 texts...\n",
      "Dataset is large (107922 texts). Sampling to 10000 for analysis to avoid memory issues.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acd8f9ecb974482bc9f04427e780079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 07:08:06,094 - BERTopic - Embedding - Completed âœ“\n",
      "2026-02-02 07:08:06,095 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-02-02 07:08:13,935 - BERTopic - Dimensionality - Completed âœ“\n",
      "2026-02-02 07:08:13,936 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-02-02 07:08:14,377 - BERTopic - Cluster - Completed âœ“\n",
      "2026-02-02 07:08:14,377 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2026-02-02 07:08:14,411 - BERTopic - Representation - Completed âœ“\n",
      "2026-02-02 07:08:14,411 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2026-02-02 07:08:14,415 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-02-02 07:08:14,444 - BERTopic - Representation - Completed âœ“\n",
      "2026-02-02 07:08:14,445 - BERTopic - Topic reduction - Reduced number of topics from 32 to 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ BERTopic identified 21 topics (excluding outliers)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4986</td>\n",
       "      <td>-1_needs_correction_needs correction_correctio...</td>\n",
       "      <td>[needs, correction, needs correction, correcti...</td>\n",
       "      <td>[Needs Correction- Clarification, Needs Correc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1056</td>\n",
       "      <td>0_wine_wine wine_label_distilled</td>\n",
       "      <td>[wine, wine wine, label, distilled, spirits]</td>\n",
       "      <td>[Wine, Wine, Wine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>1_label_labeling_request labeling_status request</td>\n",
       "      <td>[label, labeling, request labeling, status req...</td>\n",
       "      <td>[Status Request -Labeling, Status Request -Lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>331</td>\n",
       "      <td>2_user registration_user_registration_new user</td>\n",
       "      <td>[user registration, user, registration, new us...</td>\n",
       "      <td>[New User Registration, New User Registration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>304</td>\n",
       "      <td>3_formulation formulation_formulation_question...</td>\n",
       "      <td>[formulation formulation, formulation, questio...</td>\n",
       "      <td>[Formulation, Formulation, Formulation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>279</td>\n",
       "      <td>4_formula_status_formula inquiry_status formula</td>\n",
       "      <td>[formula, status, formula inquiry, status form...</td>\n",
       "      <td>[Status of Formula Inquiry, Status of Formula ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>247</td>\n",
       "      <td>5_cola_colas_online_assistance</td>\n",
       "      <td>[cola, colas, online, assistance, submit]</td>\n",
       "      <td>[COLAS online is down, Needed assistance with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>241</td>\n",
       "      <td>6_call_password_reset_phone</td>\n",
       "      <td>[call, password, reset, phone, transferred]</td>\n",
       "      <td>[PASSWORD RESET, Password reset assistance. Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>7_allowable revisions_revisions_allowable_impo...</td>\n",
       "      <td>[allowable revisions, revisions, allowable, im...</td>\n",
       "      <td>[Allowable Revisions, Allowable Revisions, All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>210</td>\n",
       "      <td>8_issues cola_issues_fonl issues_cola fonl</td>\n",
       "      <td>[issues cola, issues, fonl issues, cola fonl, ...</td>\n",
       "      <td>[COLA/FONL Issues, COLA/FONL Issues, COLA/FONL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>185</td>\n",
       "      <td>9_permit_nrc_applicant_sa</td>\n",
       "      <td>[permit, nrc, applicant, sa, poa]</td>\n",
       "      <td>[NRC, NRC, NRC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "      <td>10_cola technical_technical issues_technical_i...</td>\n",
       "      <td>[cola technical, technical issues, technical, ...</td>\n",
       "      <td>[COLA Technical Issues, COLA Technical Issues,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>11_soc_corrections_correction_received</td>\n",
       "      <td>[soc, corrections, correction, received, request]</td>\n",
       "      <td>[soc needs correction explained., IM needed as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>157</td>\n",
       "      <td>12_questions labeling_labeling questions_label...</td>\n",
       "      <td>[questions labeling, labeling questions, label...</td>\n",
       "      <td>[Labeling Questions, Labeling Questions, Label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>150</td>\n",
       "      <td>13_inquiry general_general inquiry_general_inq...</td>\n",
       "      <td>[inquiry general, general inquiry, general, in...</td>\n",
       "      <td>[General Inquiry, General Inquiry, General Inq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>141</td>\n",
       "      <td>14_malt beverage_malt_beverage_beverage malt</td>\n",
       "      <td>[malt beverage, malt, beverage, beverage malt,...</td>\n",
       "      <td>[Malt Beverage, Malt Beverage, Malt Beverage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>136</td>\n",
       "      <td>15_ingredients_ingredients ingredients_fonl te...</td>\n",
       "      <td>[ingredients, ingredients ingredients, fonl te...</td>\n",
       "      <td>[Ingredients, Ingredients, Ingredients]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>131</td>\n",
       "      <td>16_spirits distilled_distilled_distilled spiri...</td>\n",
       "      <td>[spirits distilled, distilled, distilled spiri...</td>\n",
       "      <td>[Distilled Spirits, Distilled Spirits, Distill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>122</td>\n",
       "      <td>17____</td>\n",
       "      <td>[, , , , ]</td>\n",
       "      <td>[Other, Other, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>106</td>\n",
       "      <td>18_ttb help_help desk_desk_help</td>\n",
       "      <td>[ttb help, help desk, desk, help, fonl]</td>\n",
       "      <td>[TTB Help Desk, TTB Help Desk, TTB Help Desk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>103</td>\n",
       "      <td>19_alcohol_beer_alcohol content_content</td>\n",
       "      <td>[alcohol, beer, alcohol content, content, stat...</td>\n",
       "      <td>[Intra-State Beer, Question about alcohol cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name  \\\n",
       "0      -1   4986  -1_needs_correction_needs correction_correctio...   \n",
       "1       0   1056                   0_wine_wine wine_label_distilled   \n",
       "2       1    438   1_label_labeling_request labeling_status request   \n",
       "3       2    331     2_user registration_user_registration_new user   \n",
       "4       3    304  3_formulation formulation_formulation_question...   \n",
       "5       4    279    4_formula_status_formula inquiry_status formula   \n",
       "6       5    247                     5_cola_colas_online_assistance   \n",
       "7       6    241                        6_call_password_reset_phone   \n",
       "8       7    226  7_allowable revisions_revisions_allowable_impo...   \n",
       "9       8    210         8_issues cola_issues_fonl issues_cola fonl   \n",
       "10      9    185                          9_permit_nrc_applicant_sa   \n",
       "11     10    177  10_cola technical_technical issues_technical_i...   \n",
       "12     11    175             11_soc_corrections_correction_received   \n",
       "13     12    157  12_questions labeling_labeling questions_label...   \n",
       "14     13    150  13_inquiry general_general inquiry_general_inq...   \n",
       "15     14    141       14_malt beverage_malt_beverage_beverage malt   \n",
       "16     15    136  15_ingredients_ingredients ingredients_fonl te...   \n",
       "17     16    131  16_spirits distilled_distilled_distilled spiri...   \n",
       "18     17    122                                             17____   \n",
       "19     18    106                    18_ttb help_help desk_desk_help   \n",
       "20     19    103            19_alcohol_beer_alcohol content_content   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [needs, correction, needs correction, correcti...   \n",
       "1        [wine, wine wine, label, distilled, spirits]   \n",
       "2   [label, labeling, request labeling, status req...   \n",
       "3   [user registration, user, registration, new us...   \n",
       "4   [formulation formulation, formulation, questio...   \n",
       "5   [formula, status, formula inquiry, status form...   \n",
       "6           [cola, colas, online, assistance, submit]   \n",
       "7         [call, password, reset, phone, transferred]   \n",
       "8   [allowable revisions, revisions, allowable, im...   \n",
       "9   [issues cola, issues, fonl issues, cola fonl, ...   \n",
       "10                  [permit, nrc, applicant, sa, poa]   \n",
       "11  [cola technical, technical issues, technical, ...   \n",
       "12  [soc, corrections, correction, received, request]   \n",
       "13  [questions labeling, labeling questions, label...   \n",
       "14  [inquiry general, general inquiry, general, in...   \n",
       "15  [malt beverage, malt, beverage, beverage malt,...   \n",
       "16  [ingredients, ingredients ingredients, fonl te...   \n",
       "17  [spirits distilled, distilled, distilled spiri...   \n",
       "18                                         [, , , , ]   \n",
       "19            [ttb help, help desk, desk, help, fonl]   \n",
       "20  [alcohol, beer, alcohol content, content, stat...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [Needs Correction- Clarification, Needs Correc...  \n",
       "1                                  [Wine, Wine, Wine]  \n",
       "2   [Status Request -Labeling, Status Request -Lab...  \n",
       "3   [New User Registration, New User Registration,...  \n",
       "4             [Formulation, Formulation, Formulation]  \n",
       "5   [Status of Formula Inquiry, Status of Formula ...  \n",
       "6   [COLAS online is down, Needed assistance with ...  \n",
       "7   [PASSWORD RESET, Password reset assistance. Tr...  \n",
       "8   [Allowable Revisions, Allowable Revisions, All...  \n",
       "9   [COLA/FONL Issues, COLA/FONL Issues, COLA/FONL...  \n",
       "10                                    [NRC, NRC, NRC]  \n",
       "11  [COLA Technical Issues, COLA Technical Issues,...  \n",
       "12  [soc needs correction explained., IM needed as...  \n",
       "13  [Labeling Questions, Labeling Questions, Label...  \n",
       "14  [General Inquiry, General Inquiry, General Inq...  \n",
       "15      [Malt Beverage, Malt Beverage, Malt Beverage]  \n",
       "16            [Ingredients, Ingredients, Ingredients]  \n",
       "17  [Distilled Spirits, Distilled Spirits, Distill...  \n",
       "18                              [Other, Other, Other]  \n",
       "19      [TTB Help Desk, TTB Help Desk, TTB Help Desk]  \n",
       "20  [Intra-State Beer, Question about alcohol cont...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Apply BERTopic for theme extraction\n",
    "model_choice = globals().get('model_choice', 'bertopic')\n",
    "sampling_max = 50000\n",
    "# Set default sample size for large datasets\n",
    "sample_size = globals().get('sample_size', 10000)\n",
    "\n",
    "if all_texts:\n",
    "    print(f\"Running {model_choice.upper()} analysis on {len(all_texts)} texts...\")\n",
    "    \n",
    "    # Handle large datasets by sampling\n",
    "    if len(all_texts) > sampling_max:\n",
    "        print(f\"Dataset is large ({len(all_texts)} texts). Sampling to {sample_size} for analysis to avoid memory issues.\")\n",
    "        sample_indices = np.random.choice(len(all_texts), sample_size, replace=False)\n",
    "        analysis_texts = [all_texts[i] for i in sample_indices]\n",
    "        analysis_sources = [text_sources[i] for i in sample_indices]\n",
    "    else:\n",
    "        analysis_texts = all_texts\n",
    "        analysis_sources = text_sources\n",
    "    \n",
    "    # Initialize BERTopic model with optimized settings for large datasets\n",
    "    topic_model = BERTopic(\n",
    "        language=\"english\",\n",
    "        calculate_probabilities=True,  # Set to False to reduce memory usage\n",
    "        verbose=True,\n",
    "        min_topic_size=20,  # Increased from 5 to reduce number of topics and memory\n",
    "        top_n_words=5,\n",
    "        nr_topics=\"auto\",   # Auto-determine number of topics\n",
    "        low_memory=True,  # Enable low memory mode for large datasets\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        # umap_model=UMAP(n_jobs=1),  # Disable multiprocessing in UMAP\n",
    "        # hdbscan_model=HDBSCAN(core_dist_n_jobs=1)  # Disable multiprocessing in HDBSCAN\n",
    "        embedding_model=embedding_model,\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    topics, probabilities = topic_model.fit_transform(analysis_texts)\n",
    "    \n",
    "    # Get topic information\n",
    "    theme_info = topic_model.get_topic_info()\n",
    "    \n",
    "    print(f\"\\nâœ“ BERTopic identified {len(theme_info)-1} topics (excluding outliers)\")\n",
    "    \n",
    "    # Display extracted themes\n",
    "    display(theme_info.head(len(theme_info)-1))\n",
    "    \n",
    "else:\n",
    "    print(\"No texts available for analysis. Please check Step 2.\")\n",
    "    theme_info = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44012421",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n",
      "Dataset size: 10000 texts, 22 topics\n",
      "\n",
      "Generating topic barchart...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top 15 Topics by Frequency</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.3.1.min.js\" integrity=\"sha256-4rD3fugVb/nVJYUv5Ky3v+fYXoouHaBSP20WIJuEiWg=\" crossorigin=\"anonymous\"></script>                <div id=\"ca97d6b3-ebf0-4c2a-bc25-7028b7f419d4\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"ca97d6b3-ebf0-4c2a-bc25-7028b7f419d4\")) {                    Plotly.newPlot(                        \"ca97d6b3-ebf0-4c2a-bc25-7028b7f419d4\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.02545251309651569,0.025741924326686295,0.026746119196688314,0.10422615710400387,0.12389708451077568],\"y\":[\"spirits  \",\"distilled  \",\"label  \",\"wine wine  \",\"wine  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.045842781946643874,0.05016326171089886,0.05094706267513165,0.05549955943127913,0.07651951090450015],\"y\":[\"request  \",\"status request  \",\"request labeling  \",\"labeling  \",\"label  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.10239334770475257,0.12573884851472183,0.15371537540572297,0.1629961247236174,0.17140427814003906],\"y\":[\"new  \",\"new user  \",\"registration  \",\"user  \",\"user registration  \"],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#E69F00\"},\"orientation\":\"h\",\"x\":[0.11335127626462771,0.20065982151074988,0.22310921797120759,0.5616473931427752,0.7053910517308779],\"y\":[\"labeling questions  \",\"formulation labeling  \",\"questions formulation  \",\"formulation  \",\"formulation formulation  \"],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#56B4E9\"},\"orientation\":\"h\",\"x\":[0.03168272860209851,0.032760543970959635,0.03444095009193155,0.03465367071146031,0.14222045517980839],\"y\":[\"research  \",\"status formula  \",\"formula inquiry  \",\"status  \",\"formula  \"],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":\"#009E73\"},\"orientation\":\"h\",\"x\":[0.030186958691446775,0.03211505355449389,0.04240905775284033,0.049891858701370646,0.06274397503784349],\"y\":[\"submit  \",\"assistance  \",\"online  \",\"colas  \",\"cola  \"],\"type\":\"bar\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":\"#F0E442\"},\"orientation\":\"h\",\"x\":[0.032193874443933665,0.04063187669402452,0.045531999628984146,0.053866115106094466,0.0571925811282796],\"y\":[\"transferred  \",\"phone  \",\"reset  \",\"password  \",\"call  \"],\"type\":\"bar\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.07506916824150274,0.11378358611542486,0.15422477377992053,0.16246680558369334,0.16279962209084234],\"y\":[\"revisions allowable  \",\"importation  \",\"allowable  \",\"revisions  \",\"allowable revisions  \"],\"type\":\"bar\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.2050426152962887,0.22692406474850735,0.2287483432053702,0.25292731075457886,0.41066528013404585],\"y\":[\"cola  \",\"cola fonl  \",\"fonl issues  \",\"issues  \",\"issues cola  \"],\"type\":\"bar\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.042732750775642196,0.04320710553614902,0.04356583527867299,0.0962376357625397,0.09893034502729434],\"y\":[\"poa  \",\"sa  \",\"applicant  \",\"nrc  \",\"permit  \"],\"type\":\"bar\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"},{\"marker\":{\"color\":\"#E69F00\"},\"orientation\":\"h\",\"x\":[0.10263129708453267,0.10620860470763704,0.15305552559916255,0.17904906268839424,0.19453089517505048],\"y\":[\"standards identity  \",\"identity  \",\"technical  \",\"technical issues  \",\"cola technical  \"],\"type\":\"bar\",\"xaxis\":\"x11\",\"yaxis\":\"y11\"},{\"marker\":{\"color\":\"#56B4E9\"},\"orientation\":\"h\",\"x\":[0.029340739757399793,0.031242287059204957,0.047924232610049744,0.05964417657827511,0.07504694640190611],\"y\":[\"request  \",\"received  \",\"correction  \",\"corrections  \",\"soc  \"],\"type\":\"bar\",\"xaxis\":\"x12\",\"yaxis\":\"y12\"},{\"marker\":{\"color\":\"#009E73\"},\"orientation\":\"h\",\"x\":[0.012429646498033256,0.3553942921072766,0.38220972796925856,0.44330960206311354,0.6630193846193334],\"y\":[\"dimensions labeling  \",\"questions  \",\"labeling  \",\"labeling questions  \",\"questions labeling  \"],\"type\":\"bar\",\"xaxis\":\"x13\",\"yaxis\":\"y13\"},{\"marker\":{\"color\":\"#F0E442\"},\"orientation\":\"h\",\"x\":[0.1650733992196418,0.2987330987301469,0.35111225361532256,0.3647367621136876,0.4255926305607221],\"y\":[\"inquiry transfer  \",\"inquiry  \",\"general  \",\"general inquiry  \",\"inquiry general  \"],\"type\":\"bar\",\"xaxis\":\"x14\",\"yaxis\":\"y14\"},{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.13159547435379293,0.2228618421987747,0.2863455167932485,0.2894152180819889,0.2915191081010184],\"y\":[\"requests  \",\"beverage malt  \",\"beverage  \",\"malt  \",\"malt beverage  \"],\"type\":\"bar\",\"xaxis\":\"x15\",\"yaxis\":\"y15\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scattermap\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermap\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.825,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.825,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.825,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.275,0.45],\"showgrid\":true},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.275,0.45],\"showgrid\":true},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.275,0.45],\"showgrid\":true},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.275,0.45],\"showgrid\":true},\"xaxis13\":{\"anchor\":\"y13\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis13\":{\"anchor\":\"x13\",\"domain\":[0.0,0.175],\"showgrid\":true},\"xaxis14\":{\"anchor\":\"y14\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis14\":{\"anchor\":\"x14\",\"domain\":[0.0,0.175],\"showgrid\":true},\"xaxis15\":{\"anchor\":\"y15\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis15\":{\"anchor\":\"x15\",\"domain\":[0.0,0.175],\"showgrid\":true},\"xaxis16\":{\"anchor\":\"y16\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis16\":{\"anchor\":\"x16\",\"domain\":[0.0,0.175],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 2\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 3\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 4\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.7250000000000001,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 5\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.7250000000000001,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 6\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.7250000000000001,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 7\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.7250000000000001,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 8\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 9\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 10\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 11\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 12\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.175,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 13\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.175,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 14\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.175,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1000,\"height\":1000},                        {\"responsive\": true}                    )                };            </script>        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Visualization complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Visualize topics\n",
    "# Safely get variables that may not exist in the current kernel/session\n",
    "# theme_info = globals().get('theme_info', None)\n",
    "# model_choice = globals().get('model_choice', 'bertopic')\n",
    "# topic_model = globals().get('topic_model', None)\n",
    "# analysis_texts = globals().get('analysis_texts', [])\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import plotly.io as pio\n",
    "\n",
    "# CRITICAL: Use 'json' renderer to prevent auto-display blocking\n",
    "# This allows manual HTML embedding via _display_fig() without hanging\n",
    "try:\n",
    "    pio.renderers.default = 'json'\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def _display_fig(fig, title=None):\n",
    "    \"\"\"Embed a Plotly figure as HTML to avoid renderer blocking issues.\"\"\"\n",
    "    try:\n",
    "        html = fig.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "        if title:\n",
    "            display(HTML(f\"<h4>{title}</h4>\"))\n",
    "        display(HTML(html))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to render figure as HTML: {e}\")\n",
    "\n",
    "if theme_info is not None and topic_model is not None:\n",
    "    print(\"Generating visualization...\")\n",
    "    print(f\"Dataset size: {len(analysis_texts)} texts, {len(theme_info)} topics\")\n",
    "    \n",
    "    # Topic distribution bar chart - fast and informative\n",
    "    try:\n",
    "        print(\"\\nGenerating topic barchart...\")\n",
    "        fig_barchart = topic_model.visualize_barchart(top_n_topics=15)\n",
    "        _display_fig(fig_barchart, title='Top 15 Topics by Frequency')\n",
    "        print(\"\\nâœ“ Visualization complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Barchart visualization failed: {e}\")\n",
    "    \n",
    "else:\n",
    "    if theme_info is None:\n",
    "        print(\"No themes available for visualization. Run the analysis cells first.\")\n",
    "    elif model_choice == 'bertopic' and topic_model is None:\n",
    "        print(\"BERTopic model object not found in the session. Re-run the BERTopic analysis cell.\")\n",
    "    else:\n",
    "        print(\"No visualizations available for the current configuration.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed4eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Themes exported to '../data/results/extracted_themes_bertopic.csv'\n",
      "âœ“ Detailed themes exported to '../data/results/detailed_themes_bertopic.csv'\n",
      "âœ“ Text-topic assignments exported to '../data/results/text_topic_assignments_bertopic.csv'\n",
      "\n",
      "==================================================\n",
      "EXPORT COMPLETE\n",
      "==================================================\n",
      "Files ready for import into QDA tools like:\n",
      "- Taguette (import CSV files)\n",
      "- QualCoder (import CSV files)\n",
      "- NVivo (import CSV files)\n",
      "- ATLAS.ti (import CSV files)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Export themes for validation/import into QDA tool\n",
    "if theme_info is not None:\n",
    "    # Export to CSV\n",
    "    output_file = f\"../data/results/extracted_themes_{model_choice}.csv\"\n",
    "    theme_info.to_csv(output_file, index=False)\n",
    "    print(f\"âœ“ Themes exported to '{output_file}'\")\n",
    "    \n",
    "    # Export detailed topic information\n",
    "    # Get topic representations\n",
    "    topic_representations = {}\n",
    "    for topic_id in theme_info['Topic'].unique():\n",
    "        if topic_id != -1:  # Skip outlier topic\n",
    "            words = topic_model.get_topic(topic_id)\n",
    "            topic_representations[topic_id] = words\n",
    "    \n",
    "    # Create detailed export\n",
    "    detailed_themes = []\n",
    "    for topic_id, words in topic_representations.items():\n",
    "        detailed_themes.append({\n",
    "            'topic_id': topic_id,\n",
    "            'topic_name': f\"Topic_{topic_id}\",\n",
    "            'top_words': ', '.join([word for word, _ in words[:10]]),\n",
    "            'word_scores': ', '.join([f\"{word}:{score:.3f}\" for word, score in words[:10]]),\n",
    "            'document_count': theme_info[theme_info['Topic'] == topic_id]['Count'].iloc[0]\n",
    "        })\n",
    "    \n",
    "    detailed_df = pd.DataFrame(detailed_themes)\n",
    "    detailed_output = f\"../data/results/detailed_themes_{model_choice}.csv\"\n",
    "    detailed_df.to_csv(detailed_output, index=False)\n",
    "    print(f\"âœ“ Detailed themes exported to '{detailed_output}'\")\n",
    "    \n",
    "    # Export text-topic assignments for QDA validation\n",
    "    text_topics_df = pd.DataFrame({\n",
    "        'text': analysis_texts,\n",
    "        'source': analysis_sources,\n",
    "        'topic': topics,\n",
    "        'topic_probability': [None] * len(topics)  # Probabilities disabled for memory efficiency\n",
    "    })\n",
    "\n",
    "    \n",
    "    assignments_file = f\"../data/results/text_topic_assignments_{model_choice}.csv\"\n",
    "    text_topics_df.to_csv(assignments_file, index=False)\n",
    "    print(f\"âœ“ Text-topic assignments exported to '{assignments_file}'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPORT COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Files ready for import into QDA tools like:\")\n",
    "    print(\"- Taguette (import CSV files)\")\n",
    "    print(\"- QualCoder (import CSV files)\")\n",
    "    print(\"- NVivo (import CSV files)\")\n",
    "    print(\"- ATLAS.ti (import CSV files)\")\n",
    "    \n",
    "else:\n",
    "    print(\"No themes to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b682b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Validate AI-generated themes** in your QDA tool\n",
    "2. **Refine topics** by merging, splitting, or renaming as needed\n",
    "3. **Code additional texts** using the validated themes\n",
    "4. **Export coded data** for further quantitative analysis\n",
    "\n",
    "## Tips for Better Results\n",
    "\n",
    "- **Preprocessing**: Clean your text data before analysis (remove noise, standardize formats)\n",
    "- **Model Tuning**: Adjust `min_topic_size` in BERTopic for more/fewer topics\n",
    "- **Language**: Set the correct language if your texts aren't in English\n",
    "- **Scale**: For large datasets (>10k texts), consider running on Databricks Community Edition\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Memory issues**: Reduce `min_topic_size` or use Top2Vec instead\n",
    "- **Poor topics**: Preprocess text better or try different model settings\n",
    "- **No texts found**: Check column names in your Excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
